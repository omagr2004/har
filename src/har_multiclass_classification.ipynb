{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Data Subset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "def load_data():\n",
    "    # Load training data\n",
    "    X_train = pd.read_csv('../data/UCI HAR Dataset/train/X_train.txt', sep='\\\\s+', header=None)\n",
    "    y_train = pd.read_csv('../data/UCI HAR Dataset/train/y_train.txt', sep='\\\\s+', header=None)\n",
    "    \n",
    "    # Load test data\n",
    "    X_test = pd.read_csv('../data/UCI HAR Dataset/test/X_test.txt', sep='\\\\s+', header=None)\n",
    "    y_test = pd.read_csv('../data/UCI HAR Dataset/test/y_test.txt', sep='\\\\s+', header=None)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "def balance_data(X,y):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote = SMOTE()\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X_train, y_train = balance_data(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Segment the data into fixed-size windows\n",
    "def segment_data(X, window_size=128):\n",
    "    segments = []\n",
    "    for start in range(0, len(X) - window_size + 1, window_size):\n",
    "        segment = X[start:start + window_size]\n",
    "        segments.append(segment)\n",
    "    return np.array(segments)\n",
    "\n",
    "# Updated segment_labels to extract a scalar label for each segment\n",
    "def segment_labels(y, window_size=128):\n",
    "    segments = []\n",
    "    for start in range(0, len(y) - window_size + 1, window_size):\n",
    "        segment = y[start:start + window_size]\n",
    "        # If y is a DataFrame use y.iloc[start, 0]; if a Series, use int(y.iloc[0])\n",
    "        segments.append(int(y.iloc[start, 0]))\n",
    "    return np.array(segments)\n",
    "\n",
    "X_train_segments = segment_data(X_train_scaled)\n",
    "X_test_segments = segment_data(X_test_scaled)\n",
    "y_train_segments = segment_labels(y_train)\n",
    "y_test_segments = segment_labels(y_test)\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_segments, y_train_segments, test_size=0.2, random_state=42)\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_segments), y=y_train_segments)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2037037  0.98484848 0.83333333 1.08333333 1.08333333 0.90277778]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(class_weights)\n",
    "unique , counts = np.unique(y_train_segments, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout,LSTM, GRU,BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping ,ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">107,776</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">606</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m107,776\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m91,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m80,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m606\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,186</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m315,186\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">315,186</span> (1.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m315,186\u001b[0m (1.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "# Convert the labels to categorical\n",
    "y_train_split_cat = to_categorical(y_train_split-1)\n",
    "y_val_split_cat = to_categorical(y_val_split-1)\n",
    "y_test_cat = to_categorical(y_test_segments-1)\n",
    "\n",
    "\n",
    "# Build a simple CNN model with Dropout layers\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.27),\n",
    "        Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.27),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        # Dropout(0.2),\n",
    "        LSTM(100),\n",
    "        Dropout(0.27),\n",
    "        Dense(100, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        # Dropout(0.3),\n",
    "        Dense(6, activation='softmax')\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "input_shape = (X_train_segments.shape[1], X_train_segments.shape[2])\n",
    "model = build_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 554ms/step - accuracy: 0.1883 - loss: 1.8187 - val_accuracy: 0.1538 - val_loss: 1.9377 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.1546 - loss: 1.7962 - val_accuracy: 0.1538 - val_loss: 1.9197 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2965 - loss: 1.7463 - val_accuracy: 0.1538 - val_loss: 1.9767 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.3093 - loss: 1.7126 - val_accuracy: 0.3077 - val_loss: 1.9056 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3141 - loss: 1.6202 - val_accuracy: 0.3077 - val_loss: 1.8786 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.5232 - loss: 1.5528 - val_accuracy: 0.3077 - val_loss: 1.8673 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.4688 - loss: 1.5310 - val_accuracy: 0.2308 - val_loss: 1.8097 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5385 - loss: 1.4070 - val_accuracy: 0.3077 - val_loss: 1.7543 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5849 - loss: 1.3029 - val_accuracy: 0.3846 - val_loss: 1.7399 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.6675 - loss: 1.2114 - val_accuracy: 0.3846 - val_loss: 1.7491 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.6186 - loss: 1.1312 - val_accuracy: 0.3846 - val_loss: 1.7730 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.6883 - loss: 1.0036 - val_accuracy: 0.3846 - val_loss: 1.7671 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.6675 - loss: 0.9440 - val_accuracy: 0.3846 - val_loss: 1.7559 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.6883 - loss: 0.9706 - val_accuracy: 0.3846 - val_loss: 1.7364 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6907 - loss: 0.8594 - val_accuracy: 0.4615 - val_loss: 1.7163 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7372 - loss: 0.7916 - val_accuracy: 0.4615 - val_loss: 1.6489 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6907 - loss: 0.8013 - val_accuracy: 0.4615 - val_loss: 1.5535 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.7372 - loss: 0.6830 - val_accuracy: 0.3846 - val_loss: 1.4705 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.7604 - loss: 0.6918 - val_accuracy: 0.4615 - val_loss: 1.4000 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.7861 - loss: 0.6322 - val_accuracy: 0.5385 - val_loss: 1.3725 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.7732 - loss: 0.5760 - val_accuracy: 0.5385 - val_loss: 1.3731 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8558 - loss: 0.5253 - val_accuracy: 0.4615 - val_loss: 1.3406 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8686 - loss: 0.4532 - val_accuracy: 0.5385 - val_loss: 1.3019 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8325 - loss: 0.4864 - val_accuracy: 0.5385 - val_loss: 1.3281 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8197 - loss: 0.4571 - val_accuracy: 0.4615 - val_loss: 1.5394 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8197 - loss: 0.4821 - val_accuracy: 0.4615 - val_loss: 1.3579 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7861 - loss: 0.4484 - val_accuracy: 0.5385 - val_loss: 1.3066 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8125 - loss: 0.4651\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8221 - loss: 0.4500 - val_accuracy: 0.4615 - val_loss: 1.3777 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the training function outside the loop to avoid retracing\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def model_predict(inputs):\n",
    "    return model(inputs)\n",
    "\n",
    "# class_weights = {0: 1.0, 1: 2.0}  # Class weights for ternary classification\n",
    "# Train the model\n",
    "history = model.fit(X_train_split, y_train_split_cat, epochs=50, \n",
    "                    batch_size=32, validation_data=(X_val_split, y_val_split_cat),\n",
    "                    class_weight=class_weights_dict, callbacks=[early_stop,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 4 evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6956521739130435\n",
      "Precision: 0.7210144927536232\n",
      "Recall: 0.6956521739130435\n",
      "F1 Score: 0.6927536231884057\n",
      "Confusion Matrix:\n",
      "[[3 0 1 0 0 0]\n",
      " [0 2 1 0 1 0]\n",
      " [0 1 2 0 0 0]\n",
      " [0 0 0 4 0 0]\n",
      " [0 0 0 2 3 0]\n",
      " [1 0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "import json\n",
    "# Evaluate the model\n",
    "y_pred = model_predict(X_test_segments)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test_cat, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "precision = precision_score(y_true_classes, y_pred_classes, average='weighted',zero_division=0)\n",
    "recall = recall_score(y_true_classes, y_pred_classes, average='weighted',zero_division=0)\n",
    "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Save the evaluation metrics in a JSON file\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'confusion_matrix': conf_matrix.tolist()\n",
    "}\n",
    "\n",
    "with open('../outputs/har_multiclass_classifier_metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('../outputs/har_multiclass_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
